"""
P0 HOTFIX - ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ v12

1. match_percent clamp (0..100)
2. Negative keywords Ð´Ð»Ñ Ð¿Ð»Ð¾Ñ…Ð¸Ñ… Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹
3. Improved pack parsing
4. Better brand matching
5. Structured logging
"""
import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional

logger = logging.getLogger(__name__)

# ==================== 1) MATCH PERCENT FIX ====================

def calculate_match_percent(confidence: float, score_raw: float = None) -> int:
    """Calculate match_percent with strict 0..100 clamp
    
    Args:
        confidence: Confidence from mapper (0..1)
        score_raw: Optional raw score for logging
    
    Returns:
        int in range 0..100
    """
    # Convert confidence to percentage
    match_pct = confidence * 100
    
    # STRICT CLAMP
    match_pct = max(0, min(100, match_pct))
    
    return int(match_pct)


# ==================== 2) NEGATIVE KEYWORDS ====================

NEGATIVE_KEYWORDS = {
    'meat.beef': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»', 'Ñ‚Ð¾Ñ„Ñƒ', 'substitute', 'ÑÐ¾ÑÐ¸ÑÐº', 'ÐºÐ¾Ð»Ð±Ð°Ñ'],  # Ð“Ð¾Ð²ÑÐ´Ð¸Ð½Ð° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð»Ð¸ ÐºÐ¾Ð»Ð±Ð°ÑÐ¾Ð¹
    'meat.pork': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»'],
    'meat.chicken': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»'],
    'dairy.ÑÑ‹Ñ€': ['ÑÑ‹Ñ€Ð½Ð¸Ðº'],  # Ð¡Ñ‹Ñ€ Ð½Ðµ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ ÑÑ‹Ñ€Ð½Ð¸ÐºÐ°Ð¼Ð¸
    'dairy.cheese': ['ÑÑ‹Ñ€Ð½Ð¸Ðº', 'cheesecake'],
    'seafood.shrimp': [],  # ÐšÑ€ÐµÐ²ÐµÑ‚ÐºÐ¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ OK
    'condiments.spice': [],  # Wide category - Ð±ÑƒÐ´ÐµÐ¼ Ð¿Ð¾Ð»Ð°Ð³Ð°Ñ‚ÑŒÑÑ Ð½Ð° product-specific Ð»Ð¾Ð³Ð¸ÐºÑƒ
    'staples.flour.wheat': ['Ñ€Ð¶Ð°Ð½', 'rye', 'Ð¼Ð°ÐºÐ°Ñ€Ð¾Ð½', 'pasta'],  # ÐŸÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ Ð¼ÑƒÐºÐ° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ Ñ€Ð¶Ð°Ð½Ð¾Ð¹
    'staples.flour.rye': ['Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat'],  # Ð Ð¶Ð°Ð½Ð°Ñ Ð¼ÑƒÐºÐ° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ Ð¿ÑˆÐµÐ½Ð¸Ñ‡Ð½Ð¾Ð¹
}

def has_negative_keywords(product_name: str, super_class: str) -> Tuple[bool, str]:
    """Check if product contains FORBIDDEN tokens for this category
    
    Returns:
        (has_negative, keyword_found)
    """
    if not super_class or super_class not in NEGATIVE_KEYWORDS:
        return False, ""
    
    name_lower = product_name.lower()
    
    for neg_keyword in NEGATIVE_KEYWORDS[super_class]:
        if neg_keyword in name_lower:
            return True, neg_keyword
    
    return False, ""


# REQUIRED ANCHORS - Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ (ÐµÑÐ»Ð¸ ÐÐ•Ð¢ = ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚ Ð²Ñ‹ÐºÐ¸Ð´Ñ‹Ð²Ð°ÐµÑ‚ÑÑ)
REQUIRED_ANCHORS = {
    'dairy.ÑÑ‹Ñ€': ['ÑÑ‹Ñ€', 'cheese', 'mozzarella', 'Ð¼Ð¾Ñ†Ð°Ñ€ÐµÐ»Ð»', 'Ð¿Ð°Ñ€Ð¼ÐµÐ·Ð°Ð½', 'Ð³Ð°ÑƒÐ´Ð°', 'Ñ‡ÐµÐ´Ð´ÐµÑ€', 'Ñ„ÐµÑ‚Ð°', 'Ð±Ñ€Ñ‹Ð½Ð·', 'ÑÑƒÐ»ÑƒÐ³ÑƒÐ½'],
    'dairy.cheese': ['ÑÑ‹Ñ€', 'cheese', 'mozzarella', 'Ð¿Ð°Ñ€Ð¼ÐµÐ·Ð°Ð½'],
    'meat.beef': ['Ð³Ð¾Ð²ÑÐ´Ð¸Ð½', 'beef'],
    'meat.pork': ['ÑÐ²Ð¸Ð½Ð¸Ð½', 'pork'],
    'meat.chicken': ['ÐºÑƒÑ€Ð¸Ð½', 'chicken', 'Ñ†Ñ‹Ð¿Ð»'],
    'meat.turkey': ['Ð¸Ð½Ð´ÐµÐ¹Ðº', 'turkey'],
    'seafood.salmon': ['Ð»Ð¾ÑÐ¾Ñ', 'ÑÐµÐ¼Ð³', 'salmon'],
    'seafood.shrimp': ['ÐºÑ€ÐµÐ²ÐµÑ‚Ðº', 'shrimp', 'prawn'],
    'seafood.seabass': ['ÑÐ¸Ð±Ð°Ñ', 'seabass'],
    'seafood.pollock': ['Ð¼Ð¸Ð½Ñ‚Ð°Ð¹', 'pollock'],
    'condiments.ketchup': ['ÐºÐµÑ‚Ñ‡ÑƒÐ¿', 'ketchup'],
    'condiments.mayo': ['Ð¼Ð°Ð¹Ð¾Ð½ÐµÐ·', 'mayo'],
    'condiments.wasabi': ['Ð²Ð°ÑÐ°Ð±Ð¸', 'wasabi'],  # Ð’Ð°ÑÐ°Ð±Ð¸ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ñ‹Ðµ anchors
    'condiments.spice': [],  # Wide category - use dynamic anchors from reference
    'staples.flour': [],  # Wide category - use dynamic anchors from reference
    'staples.Ð¼ÑƒÐºÐ°': [],  # Wide category (Russian) - use dynamic anchors from reference
    'staples.flour.wheat': ['Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat'],  # ÐŸÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ Ð¼ÑƒÐºÐ°
    'staples.flour.rye': ['Ñ€Ð¶Ð°Ð½', 'rye'],  # Ð Ð¶Ð°Ð½Ð°Ñ Ð¼ÑƒÐºÐ°
}


def has_required_anchors(candidate_name: str, super_class: str, reference_name: str = None) -> Tuple[bool, str]:
    """Check if candidate contains REQUIRED anchor tokens for this category
    
    ENHANCED: If super_class is wide (e.g., condiments.spice), use reference_name 
    to detect specific product and require it in candidate.
    
    Args:
        candidate_name: Candidate product name
        super_class: Product category
        reference_name: Optional reference name for dynamic anchor detection
    
    Returns:
        (has_anchor, found_anchor) or (True, '') if anchors not required
    """
    if not super_class:
        return True, ""
    
    candidate_lower = candidate_name.lower()
    
    # Strategy 1: Pre-defined REQUIRED_ANCHORS
    if super_class in REQUIRED_ANCHORS:
        anchors = REQUIRED_ANCHORS[super_class]
        
        # If no anchors defined (e.g., condiments.spice), fall through to Strategy 2
        if not anchors:
            pass
        else:
            # At least ONE anchor must be present
            for anchor in anchors:
                if anchor in candidate_lower:
                    return True, anchor
            return False, ""
    
    # Strategy 2: DYNAMIC anchors from reference (for wide categories)
    # Extract specific product words from reference (e.g., "Ð²Ð°ÑÐ°Ð±Ð¸", "ÑÐ¾Ð»ÑŒ", "Ð¿ÐµÑ€ÐµÑ†", "Ð¿ÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ", "Ñ€Ð¶Ð°Ð½Ð°Ñ", "Ñ„Ð°Ñ€Ñˆ")
    if reference_name and super_class in ['condiments.spice', 'staples.flour', 'staples.Ð¼ÑƒÐºÐ°', 'meat.beef', 'other']:
        ref_lower = reference_name.lower()
        
        # List of specific product types
        specific_products = [
            'Ð²Ð°ÑÐ°Ð±Ð¸', 'wasabi',
            'ÑÐ¾Ð»ÑŒ', 'salt', 'Ð½Ð¸Ñ‚Ñ€Ð¸Ñ‚Ð½',
            'Ð¿ÐµÑ€ÐµÑ†', 'pepper',
            'Ð³Ð¾Ñ€Ñ‡Ð¸Ñ†', 'mustard',
            'Ð¸Ð¼Ð±Ð¸Ñ€', 'ginger',
            'ÐºÑƒÐ½Ð¶ÑƒÑ‚', 'sesame',
            'ÐºÐ¾Ñ€Ð¸Ð°Ð½Ð´Ñ€', 'coriander',
            'ÐºÑƒÑ€ÐºÑƒÐ¼', 'turmeric',
            'Ð¿Ð°Ð¿Ñ€Ð¸Ðº', 'paprika',
            'Ð±Ð°Ð·Ð¸Ð»Ð¸Ðº', 'basil',
            'Ð¾Ñ€ÐµÐ³Ð°Ð½Ð¾', 'oregano',
            'Ñ‚Ð¸Ð¼ÑŒÑÐ½', 'thyme',
            'Ñ€Ð¾Ð·Ð¼Ð°Ñ€Ð¸Ð½', 'rosemary',
            # ÐœÑƒÐºÐ° Ñ‚Ð¸Ð¿Ñ‹
            'Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat',
            'Ñ€Ð¶Ð°Ð½', 'rye',
            'ÐºÑƒÐºÑƒÑ€ÑƒÐ·', 'corn',
            'Ñ€Ð¸ÑÐ¾Ð²', 'rice',
            'Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²', 'buckwheat',
            'Ð¾Ð²ÑÑÐ½', 'oat',
            # ÐœÑÑÐ¾ Ñ‚Ð¸Ð¿Ñ‹
            'Ñ„Ð°Ñ€Ñˆ', 'minced', 'ground',
            'ÑÑ‚ÐµÐ¹Ðº', 'steak',
            'Ñ„Ð¸Ð»Ðµ', 'fillet',
            'Ñ€Ñ‘Ð±Ñ€', 'ribs',
            'Ð³Ñ€ÑƒÐ´Ðº', 'breast',
            'Ð±ÐµÐ´Ñ€', 'thigh'
        ]
        
        # Check if reference contains any specific product
        for product in specific_products:
            if product in ref_lower:
                # Candidate MUST also contain this product
                if product in candidate_lower:
                    return True, f"dynamic:{product}"
                else:
                    return False, f"missing:{product}"
    
    # No anchors required = pass
    return True, ""


# ==================== 3) IMPROVED PACK PARSING ====================

def parse_pack_value(product_name: str) -> Optional[float]:
    """Enhanced pack parsing with support for ranges and approximations
    
    Supports:
    - ~5ÐºÐ³, â‰ˆ5ÐºÐ³
    - 4-5 ÐºÐ³, 300-400Ð³
    - 4/5 (weight range)
    - 10Ñ…200, 6x1.5 (multipack)
    - Standard: 1ÐºÐ³, 500Ð³, 2Ð», 250Ð¼Ð»
    
    Returns:
        Pack value in base units (kg/l), or None if cannot parse
    """
    if not product_name:
        return None
    
    name = product_name.lower()
    
    # Pattern 1: Approximate (~, â‰ˆ)
    approx_patterns = [
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*ÐºÐ³', 1.0),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð³', 0.001),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð»', 1.0),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð¼Ð»', 0.001),
    ]
    
    for pattern, multiplier in approx_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                value = float(match.group(1).replace(',', '.'))
                return value * multiplier
            except:
                continue
    
    # Pattern 2: Range (300-400, 4-5)
    range_patterns = [
        (r'(\d+)[-â€“](\d+)\s*ÐºÐ³', 1.0),
        (r'(\d+)[-â€“](\d+)\s*Ð³', 0.001),
        (r'(\d+)[-â€“](\d+)\s*Ð»', 1.0),
        (r'(\d+)[-â€“](\d+)\s*Ð¼Ð»', 0.001),
        (r'(\d+)/(\d+)', 1.0),  # 4/5 (weight category)
    ]
    
    for pattern, multiplier in range_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                val1 = float(match.group(1))
                val2 = float(match.group(2))
                # Use middle of range
                value = (val1 + val2) / 2
                return value * multiplier
            except:
                continue
    
    # Pattern 3: Standard (1ÐºÐ³, 500Ð³, etc.)
    standard_patterns = [
        (r'(\d+[\.,]?\d*)\s*ÐºÐ³', 1.0),
        (r'(\d+[\.,]?\d*)\s*Ð³', 0.001),
        (r'(\d+[\.,]?\d*)\s*Ð»', 1.0),
        (r'(\d+[\.,]?\d*)\s*Ð¼Ð»', 0.001),
        (r'(\d+[\.,]?\d*)\s*ÑˆÑ‚', 1.0),
    ]
    
    for pattern, multiplier in standard_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                value = float(match.group(1).replace(',', '.'))
                return value * multiplier
            except:
                continue
    
    return None


# ==================== 4) BRAND TEXT EXTRACTION ====================

def normalize_brand_text(text: str) -> str:
    """Normalize brand text for matching
    
    - Lowercase
    - Ñ‘â†’Ðµ
    - Remove punctuation, quotes, â„¢, Â®
    - Collapse spaces
    """
    if not text:
        return ""
    
    text = str(text).upper()
    text = text.replace('Ð', 'Ð•').replace('Ñ‘', 'Ðµ')
    
    # Remove trademark symbols
    text = text.replace('â„¢', '').replace('Â®', '').replace('Â©', '')
    
    # Remove punctuation and quotes
    text = re.sub(r'["\'\Â«\Â»\.\,\;\:\!\?]', ' ', text)
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    
    # Collapse spaces
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text.lower()


def extract_brand_from_text(product_name: str, brand_aliases: dict) -> Optional[str]:
    """Extract brand_id from product name using brand_aliases
    
    Args:
        product_name: Product name
        brand_aliases: dict {alias_norm: brand_id}
    
    Returns:
        brand_id or None
    """
    if not product_name or not brand_aliases:
        return None
    
    name_norm = normalize_brand_text(product_name)
    name_words = set(name_norm.split())
    
    # Sort by length (longest first) for better matching
    sorted_aliases = sorted(brand_aliases.items(), key=lambda x: len(x[0]), reverse=True)
    
    for alias_norm, brand_id in sorted_aliases:
        # Short aliases require exact word match
        if len(alias_norm) < 4:
            if alias_norm in name_words:
                return brand_id
        else:
            # Longer aliases - substring at word boundary
            if alias_norm in name_norm:
                # Check word boundary
                pattern = r'(^|\s)' + re.escape(alias_norm) + r'($|\s)'
                if re.search(pattern, name_norm):
                    return brand_id
    
    return None


# Global brand aliases cache
_brand_aliases_cache = None

def load_brand_aliases() -> dict:
    """Load brand aliases from MongoDB
    
    Returns:
        dict {alias_norm: brand_id}
    """
    global _brand_aliases_cache
    
    if _brand_aliases_cache is not None:
        return _brand_aliases_cache
    
    try:
        from pymongo import MongoClient
        import os
        
        DB_NAME = os.environ.get('DB_NAME', 'test_database')
        db = MongoClient(os.environ.get('MONGO_URL'))[DB_NAME]
        
        # Load from brand_aliases collection
        aliases_cursor = db.brand_aliases.find({}, {'_id': 0, 'alias_norm': 1, 'brand_id': 1})
        _brand_aliases_cache = {doc['alias_norm']: doc['brand_id'] 
                                for doc in aliases_cursor if doc.get('alias_norm')}
        
        logger.info(f"ðŸ“š Loaded {len(_brand_aliases_cache)} brand aliases for text extraction")
        
    except Exception as e:
        logger.warning(f"âš ï¸ Could not load brand aliases: {e}")
        _brand_aliases_cache = {}
    
    return _brand_aliases_cache


# ==================== 4) STRUCTURED LOGGING ====================

class SearchLogger:
    """Structured logger for search operations - SAFE (never breaks search)"""
    
    def __init__(self, reference_id: str):
        self.reference_id = reference_id
        self.log_data = {
            'reference_id': reference_id,
            'timestamp': datetime.utcnow().isoformat(),
            'request_context': {},
            'pipeline_counts': {},
            'selection': {},
            'brand_diagnostics': {},
            'outcome': 'unknown'
        }
    
    def set_context(self, **kwargs):
        """SAFE: Set request context"""
        try:
            self.log_data['request_context'].update(kwargs)
        except Exception:
            pass
    
    def set_count(self, stage: str, count: int):
        """SAFE: Set pipeline count"""
        try:
            self.log_data['pipeline_counts'][stage] = count
        except Exception:
            pass
    
    def set_selection(self, **kwargs):
        """SAFE: Set selection data"""
        try:
            self.log_data['selection'].update(kwargs)
        except Exception:
            pass
    
    def set_brand_diagnostics(self, **kwargs):
        """SAFE: Set brand diagnostics"""
        try:
            self.log_data['brand_diagnostics'].update(kwargs)
        except Exception:
            pass
    
    def set_outcome(self, outcome: str, reason_code: str = None):
        """SAFE: Set outcome"""
        try:
            self.log_data['outcome'] = outcome
            if reason_code:
                self.log_data['reason_code'] = reason_code
        except Exception:
            pass
    
    def get_log(self) -> Dict:
        """Get log data"""
        return self.log_data
    
    def log(self):
        """SAFE: Write structured log (never raises)"""
        try:
            logger.info(f"SEARCH_LOG: {json.dumps(self.log_data, ensure_ascii=False)}")
        except Exception as e:
            # Fallback: minimal log
            try:
                logger.warning(f"SearchLogger error: {str(e)}")
            except:
                pass  # Silent fail - logging cannot break search
    
    def set_brand_diagnostics(self, **kwargs):
        """Set brand diagnostics for debugging brand matching"""
        if 'brand_diagnostics' not in self.log_data:
            self.log_data['brand_diagnostics'] = {}
        self.log_data['brand_diagnostics'].update(kwargs)
    
    def set_outcome(self, outcome: str, reason_code: str = None):
        self.log_data['outcome'] = outcome
        if reason_code:
            self.log_data['reason_code'] = reason_code
    
    def get_log(self) -> Dict:
        return self.log_data
    
    def log(self):
        """Write structured log"""
        logger.info(f"SEARCH_LOG: {json.dumps(self.log_data, ensure_ascii=False)}")


# ==================== TESTING ====================

if __name__ == '__main__':
    print("ðŸ§ª P0 Hotfix Components Test\n")
    
    # Test match_percent
    print("1. match_percent clamp:")
    test_values = [0.5, 1.0, 95.0, 150.0, -10.0]
    for val in test_values:
        result = calculate_match_percent(val)
        print(f"   {val:6.1f} â†’ {result} {'âœ…' if 0 <= result <= 100 else 'âŒ'}")
    
    # Test negative keywords
    print("\n2. Negative keywords:")
    test_products = [
        ("Ð“ÐžÐ’Ð¯Ð”Ð˜ÐÐ PRIME 5ÐºÐ³", "meat.beef", False),
        ("Ð ÐÐ¡Ð¢Ð˜Ð¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¡Ð¢Ð Ð˜ÐŸÐ¡Ð« Ð²Ð¼ÐµÑÑ‚Ð¾ Ð³Ð¾Ð²ÑÐ´Ð¸Ð½Ñ‹", "meat.beef", True),
        ("Ð¡Ñ‹Ñ€ Ð¼Ð¾Ñ†Ð°Ñ€ÐµÐ»Ð»Ð° 125Ð³", "dairy.ÑÑ‹Ñ€", False),
        ("Ð¡Ð«Ð ÐÐ˜ÐšÐ˜ 50Ð³", "dairy.ÑÑ‹Ñ€", True)
    ]
    
    for name, sc, expected_negative in test_products:
        has_neg, keyword = has_negative_keywords(name, sc)
        status = "âœ…" if has_neg == expected_negative else "âŒ"
        print(f"   {status} {name[:40]:40} â†’ {has_neg} ('{keyword}')")
    
    # Test pack parsing
    print("\n3. Pack parsing:")
    test_packs = [
        "Ð“Ð¾Ð²ÑÐ´Ð¸Ð½Ð° Ð Ð˜Ð‘ÐÐ™ ~5ÐºÐ³",
        "Ð¡Ð˜Ð‘ÐÐ¡ 300-400Ð³",
        "Ð Ð¸Ñ 4/5 ÐºÐ³",
        "ÐšÐµÑ‚Ñ‡ÑƒÐ¿ 800Ð³",
        "ÐœÐ°ÑÐ»Ð¾ 1,5Ð»"
    ]
    
    for product in test_packs:
        pack = parse_pack_value(product)
        print(f"   {product[:40]:40} â†’ {pack}")
    
    print("\nâœ… All components tested")
