"""
P0 HOTFIX - ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ v12

1. match_percent clamp (0..100)
2. Negative keywords Ð´Ð»Ñ Ð¿Ð»Ð¾Ñ…Ð¸Ñ… Ð¼Ð°Ñ‚Ñ‡ÐµÐ¹
3. Improved pack parsing
4. Better brand matching
5. Structured logging
6. SEED_DICT_RULES support for mandatory attributes
"""
import os
import re
import json
import logging
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from pymongo import MongoClient

logger = logging.getLogger(__name__)

# Cache for seed_dict_rules
_seed_dict_rules_cache = None

def load_seed_dict_rules():
    """Load seed_dict_rules from MongoDB (cached)"""
    global _seed_dict_rules_cache
    if _seed_dict_rules_cache is not None:
        return _seed_dict_rules_cache
    
    try:
        client = MongoClient(os.environ.get('MONGO_URL'))
        db = client[os.environ.get('DB_NAME', 'test_database')]
        rules = list(db.seed_dict_rules.find({}, {'_id': 0}))
        
        # Build lookup by type -> raw values (with action 'Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ' or 'Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾')
        _seed_dict_rules_cache = {
            'fat': [],      # Ð¶Ð¸Ñ€Ð½Ð¾ÑÑ‚ÑŒ: 0%, 1%, 3.2%, etc.
            'grade': [],    # ÑÐ¾Ñ€Ñ‚: choice, prime, Ð¿ÐµÑ€Ð²Ñ‹Ð¹_ÑÐ¾Ñ€Ñ‚, etc.
            'size': [],     # Ñ€Ð°Ð·Ð¼ÐµÑ€: 16/20, 21/25, etc. (for shrimp)
            'form': [],     # Ñ„Ð¾Ñ€Ð¼Ð°: Ð±ÐµÐ·_Ð³Ð¾Ð»Ð¾Ð²Ñ‹, Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ð°Ñ, etc.
            'process': [],  # Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°: ÑÑ‹Ñ€Ð¾Ð²ÑÐ»ÐµÐ½, Ð²Ð°Ñ€ÐµÐ½Ð¾_ÐºÐ¾Ð¿Ñ‡ÐµÐ½, etc.
        }
        
        for rule in rules:
            rule_type = rule.get('type', '').lower()
            raw_value = rule.get('raw', '').lower()
            action = rule.get('action', '')
            
            if rule_type in _seed_dict_rules_cache and raw_value:
                # Include rules with actions that mean "keep/mandatory"
                if action in ['Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ', 'Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾', 'ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ']:
                    _seed_dict_rules_cache[rule_type].append(raw_value)
        
        logger.info(f"Loaded seed_dict_rules: fat={len(_seed_dict_rules_cache['fat'])}, grade={len(_seed_dict_rules_cache['grade'])}, size={len(_seed_dict_rules_cache['size'])}")
        return _seed_dict_rules_cache
    except Exception as e:
        logger.error(f"Failed to load seed_dict_rules: {e}")
        _seed_dict_rules_cache = {'fat': [], 'grade': [], 'size': [], 'form': [], 'process': []}
        return _seed_dict_rules_cache


def extract_seed_dict_attributes(text: str) -> Dict[str, str]:
    """
    Extract seed_dict_rules attributes from product name.
    Returns dict of found attributes by type.
    """
    rules = load_seed_dict_rules()
    text_lower = text.lower()
    found = {}
    
    # Check fat percentages (e.g., "3.2%", "0%")
    fat_pattern = re.search(r'(\d+[,.]?\d*)\s*%', text)
    if fat_pattern:
        fat_value = fat_pattern.group(0).replace(',', '.')
        found['fat'] = fat_value
    
    # Check grades (choice, prime, etc.)
    for grade in rules.get('grade', []):
        if grade in text_lower:
            found['grade'] = grade
            break
    
    # Check sizes (16/20, 21/25, etc.)
    size_pattern = re.search(r'(\d+/\d+)', text)
    if size_pattern:
        found['size'] = size_pattern.group(1)
    
    return found


def check_seed_dict_match(reference_name: str, candidate_name: str) -> Tuple[bool, str]:
    """
    Check if candidate matches seed_dict_rules attributes from reference.
    
    Returns:
        (match, reason) - True if candidate has same attributes or reference has none
    """
    ref_attrs = extract_seed_dict_attributes(reference_name)
    
    if not ref_attrs:
        return True, ""  # No seed_dict attributes to match
    
    cand_attrs = extract_seed_dict_attributes(candidate_name)
    
    # Check each attribute type
    for attr_type, ref_value in ref_attrs.items():
        cand_value = cand_attrs.get(attr_type)
        
        if attr_type == 'fat':
            # Fat percentages must match exactly
            if ref_value and cand_value != ref_value:
                return False, f"fat_mismatch:{ref_value}!={cand_value}"
        
        elif attr_type == 'grade':
            # Grades must match
            if ref_value and cand_value != ref_value:
                return False, f"grade_mismatch:{ref_value}!={cand_value}"
        
        elif attr_type == 'size':
            # Sizes (shrimp) must match exactly
            if ref_value and cand_value != ref_value:
                return False, f"size_mismatch:{ref_value}!={cand_value}"
    
    return True, ""


# Price sanity thresholds by category (min expected price per kg/unit)
CATEGORY_PRICE_THRESHOLDS = {
    # Expensive natural products
    'seafood.crab.kamchatka': 2000,  # ÐšÐ°Ð¼Ñ‡Ð°Ñ‚ÑÐºÐ¸Ð¹ ÐºÑ€Ð°Ð±: min 2000â‚½/ÐºÐ³
    'seafood.crab.natural': 1500,    # ÐÐ°Ñ‚ÑƒÑ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑ€Ð°Ð±: min 1500â‚½/ÐºÐ³
    'seafood.crab.king': 2500,       # King crab: min 2500â‚½/ÐºÐ³
    'seafood.lobster': 2000,         # Ð›Ð¾Ð±ÑÑ‚ÐµÑ€: min 2000â‚½/ÐºÐ³
    'meat.beef.ribeye': 1000,        # Ð Ð¸Ð±Ð°Ð¹: min 1000â‚½/ÐºÐ³
    'meat.beef.wagyu': 3000,         # Ð’Ð°Ð³ÑŽ: min 3000â‚½/ÐºÐ³
    # Cheap imitation products
    'seafood.crab_sticks': 50,       # ÐšÑ€Ð°Ð±Ð¾Ð²Ñ‹Ðµ Ð¿Ð°Ð»Ð¾Ñ‡ÐºÐ¸: max ~300â‚½/ÐºÐ³
}


def check_price_sanity(reference_name: str, ref_price: float, candidate_name: str, cand_price: float, super_class: str) -> Tuple[bool, str]:
    """
    Check if candidate price makes sense compared to reference.
    Prevents absurd matches like natural crab (2500â‚½) â†’ crab sticks (200â‚½).
    
    Returns:
        (is_sane, reason) - True if price is reasonable
    """
    if not ref_price or not cand_price or ref_price <= 0 or cand_price <= 0:
        return True, ""
    
    # Check 1: If reference is expensive category, candidate can't be too cheap
    if super_class in CATEGORY_PRICE_THRESHOLDS:
        min_price = CATEGORY_PRICE_THRESHOLDS[super_class]
        if cand_price < min_price * 0.5:  # Allow 50% margin
            return False, f"price_too_low:{cand_price}<{min_price*0.5}"
    
    # Check 2: Price ratio sanity
    # If candidate is 5x cheaper than reference, it's suspicious
    price_ratio = ref_price / cand_price if cand_price > 0 else 999
    if price_ratio > 5:
        # Check if this is expected (e.g., bulk discount)
        ref_lower = reference_name.lower()
        cand_lower = candidate_name.lower()
        
        # Keywords that indicate premium/natural products
        premium_keywords = ['Ð½Ð°Ñ‚ÑƒÑ€', 'ÐºÐ°Ð¼Ñ‡Ð°Ñ‚', 'king', 'Ð¿Ñ€ÐµÐ¼Ð¸ÑƒÐ¼', 'prime', 'choice', 'wagyu']
        ref_is_premium = any(kw in ref_lower for kw in premium_keywords)
        cand_is_premium = any(kw in cand_lower for kw in premium_keywords)
        
        # If reference is premium but candidate is not, reject
        if ref_is_premium and not cand_is_premium:
            return False, f"premium_mismatch:ratio={price_ratio:.1f}"
    
    return True, ""

# ==================== 1) MATCH PERCENT FIX ====================

def calculate_match_percent(confidence: float, score_raw: float = None) -> int:
    """Calculate match_percent with strict 0..100 clamp
    
    Args:
        confidence: Confidence from mapper (0..1)
        score_raw: Optional raw score for logging
    
    Returns:
        int in range 0..100
    """
    # Convert confidence to percentage
    match_pct = confidence * 100
    
    # STRICT CLAMP
    match_pct = max(0, min(100, match_pct))
    
    return int(match_pct)


# ==================== 2) NEGATIVE KEYWORDS ====================

NEGATIVE_KEYWORDS = {
    'meat.beef': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»', 'Ñ‚Ð¾Ñ„Ñƒ', 'substitute', 'ÑÐ¾ÑÐ¸ÑÐº', 'ÐºÐ¾Ð»Ð±Ð°Ñ'],  # Ð“Ð¾Ð²ÑÐ´Ð¸Ð½Ð° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð±Ñ‹Ñ‚ÑŒ Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð¸Ð»Ð¸ ÐºÐ¾Ð»Ð±Ð°ÑÐ¾Ð¹
    'meat.pork': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»'],
    'meat.chicken': ['Ñ€Ð°ÑÑ‚Ð¸Ñ‚ÐµÐ»ÑŒÐ½', 'Ð²ÐµÐ³Ð°Ð½', 'ÑÐ¾ÐµÐ²', 'Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÐµÐ»'],
    'dairy.ÑÑ‹Ñ€': ['ÑÑ‹Ñ€Ð½Ð¸Ðº'],  # Ð¡Ñ‹Ñ€ Ð½Ðµ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ ÑÑ‹Ñ€Ð½Ð¸ÐºÐ°Ð¼Ð¸
    'dairy.cheese': ['ÑÑ‹Ñ€Ð½Ð¸Ðº', 'cheesecake'],
    'seafood.shrimp': [],  # ÐšÑ€ÐµÐ²ÐµÑ‚ÐºÐ¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ OK
    'condiments.spice': [],  # Wide category - Ð±ÑƒÐ´ÐµÐ¼ Ð¿Ð¾Ð»Ð°Ð³Ð°Ñ‚ÑŒÑÑ Ð½Ð° product-specific Ð»Ð¾Ð³Ð¸ÐºÑƒ
    'staples.flour.wheat': ['Ñ€Ð¶Ð°Ð½', 'rye', 'Ð¼Ð°ÐºÐ°Ñ€Ð¾Ð½', 'pasta'],  # ÐŸÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ Ð¼ÑƒÐºÐ° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ Ñ€Ð¶Ð°Ð½Ð¾Ð¹
    'staples.flour.rye': ['Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat'],  # Ð Ð¶Ð°Ð½Ð°Ñ Ð¼ÑƒÐºÐ° Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ Ñ Ð¿ÑˆÐµÐ½Ð¸Ñ‡Ð½Ð¾Ð¹
}

def has_negative_keywords(product_name: str, super_class: str) -> Tuple[bool, str]:
    """Check if product contains FORBIDDEN tokens for this category
    
    Returns:
        (has_negative, keyword_found)
    """
    if not super_class or super_class not in NEGATIVE_KEYWORDS:
        return False, ""
    
    name_lower = product_name.lower()
    
    for neg_keyword in NEGATIVE_KEYWORDS[super_class]:
        if neg_keyword in name_lower:
            return True, neg_keyword
    
    return False, ""


# REQUIRED ANCHORS - Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ (ÐµÑÐ»Ð¸ ÐÐ•Ð¢ = ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚ Ð²Ñ‹ÐºÐ¸Ð´Ñ‹Ð²Ð°ÐµÑ‚ÑÑ)
REQUIRED_ANCHORS = {
    'dairy.ÑÑ‹Ñ€': ['ÑÑ‹Ñ€', 'cheese', 'mozzarella', 'Ð¼Ð¾Ñ†Ð°Ñ€ÐµÐ»Ð»', 'Ð¿Ð°Ñ€Ð¼ÐµÐ·Ð°Ð½', 'Ð³Ð°ÑƒÐ´Ð°', 'Ñ‡ÐµÐ´Ð´ÐµÑ€', 'Ñ„ÐµÑ‚Ð°', 'Ð±Ñ€Ñ‹Ð½Ð·', 'ÑÑƒÐ»ÑƒÐ³ÑƒÐ½'],
    'dairy.cheese': ['ÑÑ‹Ñ€', 'cheese', 'mozzarella', 'Ð¿Ð°Ñ€Ð¼ÐµÐ·Ð°Ð½'],
    'meat.beef': ['Ð³Ð¾Ð²ÑÐ´Ð¸Ð½', 'beef'],
    'meat.pork': ['ÑÐ²Ð¸Ð½Ð¸Ð½', 'pork'],
    'meat.chicken': ['ÐºÑƒÑ€Ð¸Ð½', 'chicken', 'Ñ†Ñ‹Ð¿Ð»', 'ÐºÑƒÑ€Ð°', 'Ð±Ñ€Ð¾Ð¹Ð»ÐµÑ€'],  # FIX: Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° "ÐºÑƒÑ€Ð°"
    'meat.turkey': ['Ð¸Ð½Ð´ÐµÐ¹Ðº', 'turkey'],
    'seafood.salmon': ['Ð»Ð¾ÑÐ¾Ñ', 'ÑÐµÐ¼Ð³', 'salmon', 'Ñ„Ð¾Ñ€ÐµÐ»', 'Ð½ÐµÑ€Ðº', 'ÐºÐ¸Ð¶ÑƒÑ‡', 'Ð³Ð¾Ñ€Ð±ÑƒÑˆ'],  # Extended
    'seafood.shrimp': ['ÐºÑ€ÐµÐ²ÐµÑ‚Ðº', 'shrimp', 'prawn'],
    'seafood.squid': ['ÐºÐ°Ð»ÑŒÐ¼Ð°Ñ€', 'squid', 'calamari'],  # FIX: ÐºÐ°Ð»ÑŒÐ¼Ð°Ñ€ Ð¾Ð±ÑÐ·Ð°Ñ‚ÐµÐ»ÐµÐ½!
    'seafood.seabass': ['ÑÐ¸Ð±Ð°Ñ', 'seabass'],
    'seafood.pollock': ['Ð¼Ð¸Ð½Ñ‚Ð°Ð¹', 'pollock'],
    # Crab categories - CRITICAL distinction
    'seafood.crab': ['ÐºÑ€Ð°Ð±', 'crab'],
    'seafood.crab.kamchatka': ['ÐºÐ°Ð¼Ñ‡Ð°Ñ‚', 'king crab', 'Ð½Ð°Ñ‚ÑƒÑ€'],  # ÐÐ°Ñ‚ÑƒÑ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ°Ð¼Ñ‡Ð°Ñ‚ÑÐºÐ¸Ð¹
    'seafood.crab.natural': ['Ð½Ð°Ñ‚ÑƒÑ€', 'ÐºÐ°Ð¼Ñ‡Ð°Ñ‚', 'king'],  # ÐÐ°Ñ‚ÑƒÑ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑ€Ð°Ð±
    'seafood.crab_sticks': ['Ð¿Ð°Ð»Ð¾Ñ‡Ðº', 'ÑÑƒÑ€Ð¸Ð¼Ð¸', 'surimi', 'Ð¸Ð¼Ð¸Ñ‚', 'ÑÐ½ÐµÐ¶Ð½'],  # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ
    # Condiments
    'condiments.ketchup': ['ÐºÐµÑ‚Ñ‡ÑƒÐ¿', 'ketchup'],
    'condiments.mayo': ['Ð¼Ð°Ð¹Ð¾Ð½ÐµÐ·', 'mayo'],
    'condiments.wasabi': ['Ð²Ð°ÑÐ°Ð±Ð¸', 'wasabi'],
    'condiments.spice': [],  # Wide category - use dynamic anchors
    'staples.flour': [],  # Wide category - use dynamic anchors
    'staples.Ð¼ÑƒÐºÐ°': ['Ð¼ÑƒÐºÐ°', 'flour'],
    'staples.Ð¼ÑƒÐºÐ°.Ð¿ÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ': ['Ð¼ÑƒÐºÐ°', 'flour', 'Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat'],
    'staples.Ð¼ÑƒÐºÐ°.Ñ€Ð¶Ð°Ð½Ð°Ñ': ['Ð¼ÑƒÐºÐ°', 'flour', 'Ñ€Ð¶Ð°Ð½', 'rye'],
    'staples.flour.wheat': ['Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat'],
    'staples.flour.rye': ['Ñ€Ð¶Ð°Ð½', 'rye'],
}

# FORBIDDEN CROSS-MATCHES - ÑÑ‚Ð¸ Ð¿Ð°Ñ€Ñ‹ ÐÐ˜ÐšÐžÐ“Ð”Ð Ð½Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð¼Ð°Ñ‚Ñ‡Ð¸Ñ‚ÑŒÑÑ
FORBIDDEN_CROSS_MATCHES = {
    # ÐÐ°Ñ‚ÑƒÑ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑ€Ð°Ð± vs Ð¸Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ
    'seafood.crab.kamchatka': ['Ð¿Ð°Ð»Ð¾Ñ‡Ðº', 'ÑÑƒÑ€Ð¸Ð¼Ð¸', 'surimi', 'Ð¸Ð¼Ð¸Ñ‚', 'ÑÐ½ÐµÐ¶Ð½'],
    'seafood.crab.natural': ['Ð¿Ð°Ð»Ð¾Ñ‡Ðº', 'ÑÑƒÑ€Ð¸Ð¼Ð¸', 'surimi', 'Ð¸Ð¼Ð¸Ñ‚', 'ÑÐ½ÐµÐ¶Ð½'],
    # Ð˜Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ñ vs Ð½Ð°Ñ‚ÑƒÑ€Ð°Ð»ÑŒÐ½Ñ‹Ð¹
    'seafood.crab_sticks': ['ÐºÐ°Ð¼Ñ‡Ð°Ñ‚', 'Ð½Ð°Ñ‚ÑƒÑ€', 'king crab'],
    # ÐšÐ°Ð»ÑŒÐ¼Ð°Ñ€ vs Ð¿Ñ‚Ð¸Ñ†Ð°
    'seafood.squid': ['ÐºÑƒÑ€Ð¸Ð½', 'ÐºÑƒÑ€Ð°', 'chicken', 'Ñ†Ñ‹Ð¿Ð»', 'Ð¸Ð½Ð´ÐµÐ¹Ðº', 'ÑƒÑ‚Ðº', 'Ð³ÑƒÑ'],
    # ÐœÐ¾Ñ€ÐµÐ¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñ‹ vs Ð¼ÑÑÐ¾
    'seafood.shrimp': ['Ð³Ð¾Ð²ÑÐ´Ð¸Ð½', 'ÑÐ²Ð¸Ð½Ð¸Ð½', 'ÐºÑƒÑ€Ð¸Ð½', 'chicken'],
    'seafood.salmon': ['Ð³Ð¾Ð²ÑÐ´Ð¸Ð½', 'ÑÐ²Ð¸Ð½Ð¸Ð½', 'ÐºÑƒÑ€Ð¸Ð½', 'chicken'],
}


def has_required_anchors(candidate_name: str, super_class: str, reference_name: str = None) -> Tuple[bool, str]:
    """Check if candidate contains REQUIRED anchor tokens for this category
    
    ENHANCED: If super_class is wide (e.g., condiments.spice), use reference_name 
    to detect specific product and require it in candidate.
    
    Args:
        candidate_name: Candidate product name
        super_class: Product category
        reference_name: Optional reference name for dynamic anchor detection
    
    Returns:
        (has_anchor, found_anchor) or (True, '') if anchors not required
    """
    if not super_class:
        return True, ""
    
    candidate_lower = candidate_name.lower()
    ref_lower = reference_name.lower() if reference_name else ""
    
    # Strategy 0: Check FORBIDDEN_CROSS_MATCHES first
    # This prevents absurd matches like "ÐºÐ°Ð»ÑŒÐ¼Ð°Ñ€" â†’ "ÐºÑƒÑ€Ð¸Ñ†Ð°"
    if super_class in FORBIDDEN_CROSS_MATCHES:
        forbidden_tokens = FORBIDDEN_CROSS_MATCHES[super_class]
        for forbidden in forbidden_tokens:
            if forbidden in candidate_lower:
                return False, f"cross_forbidden:{forbidden}"
    
    # Strategy 1: Check DYNAMIC anchors FIRST for specific categories
    # (for shrimp sizes, flour types, etc.)
    if reference_name and super_class in ['condiments.spice', 'staples.flour', 'staples.Ð¼ÑƒÐºÐ°', 'staples.Ð¼ÑƒÐºÐ°.Ð¿ÑˆÐµÐ½Ð¸Ñ‡Ð½Ð°Ñ', 
                                           'staples.Ð¼ÑƒÐºÐ°.Ñ€Ð¶Ð°Ð½Ð°Ñ', 'meat.beef', 'seafood.shrimp', 'other']:
        
        # List of specific product attributes that MUST match
        specific_attributes = [
            # Ð Ð°Ð·Ð¼ÐµÑ€Ñ‹ ÐºÑ€ÐµÐ²ÐµÑ‚Ð¾Ðº (CRITICAL for seafood.shrimp)
            '16/20', '21/25', '26/30', '31/35', '31/40', '41/50', '51/60', '61/70',
            '71/90', '90/120', '100/150', '150/200', '200/300', '300/500',
            # Ð¡Ð¿ÐµÑ†Ð¸Ð¸
            'Ð²Ð°ÑÐ°Ð±Ð¸', 'wasabi',
            'ÑÐ¾Ð»ÑŒ', 'salt', 'Ð½Ð¸Ñ‚Ñ€Ð¸Ñ‚Ð½',
            'Ð¿ÐµÑ€ÐµÑ†', 'pepper',
            'Ð³Ð¾Ñ€Ñ‡Ð¸Ñ†', 'mustard',
            'Ð¸Ð¼Ð±Ð¸Ñ€', 'ginger',
            'ÐºÑƒÐ½Ð¶ÑƒÑ‚', 'sesame',
            'ÐºÐ¾Ñ€Ð¸Ð°Ð½Ð´Ñ€', 'coriander',
            'ÐºÑƒÑ€ÐºÑƒÐ¼', 'turmeric',
            'Ð¿Ð°Ð¿Ñ€Ð¸Ðº', 'paprika',
            'Ð±Ð°Ð·Ð¸Ð»Ð¸Ðº', 'basil',
            'Ð¾Ñ€ÐµÐ³Ð°Ð½Ð¾', 'oregano',
            'Ñ‚Ð¸Ð¼ÑŒÑÐ½', 'thyme',
            'Ñ€Ð¾Ð·Ð¼Ð°Ñ€Ð¸Ð½', 'rosemary',
            # ÐœÑƒÐºÐ° Ñ‚Ð¸Ð¿Ñ‹
            'Ð¿ÑˆÐµÐ½Ð¸Ñ‡', 'wheat',
            'Ñ€Ð¶Ð°Ð½', 'rye',
            'ÐºÑƒÐºÑƒÑ€ÑƒÐ·', 'corn',
            'Ñ€Ð¸ÑÐ¾Ð²', 'rice',
            'Ð³Ñ€ÐµÑ‡Ð½ÐµÐ²', 'buckwheat',
            'Ð¾Ð²ÑÑÐ½', 'oat',
            # ÐœÑÑÐ¾ Ñ‚Ð¸Ð¿Ñ‹
            'Ñ„Ð°Ñ€Ñˆ', 'minced', 'ground',
            'ÑÑ‚ÐµÐ¹Ðº', 'steak',
            'Ñ„Ð¸Ð»Ðµ', 'fillet',
            'Ñ€Ñ‘Ð±Ñ€', 'ribs',
            'Ð³Ñ€ÑƒÐ´Ðº', 'breast',
            'Ð±ÐµÐ´Ñ€', 'thigh',
        ]
        
        # Check if reference contains any specific attribute
        for attr in specific_attributes:
            if attr in ref_lower:
                # Candidate MUST also contain this attribute
                if attr in candidate_lower:
                    # Continue checking (may have multiple attributes)
                    continue
                else:
                    return False, f"missing:{attr}"
    
    # Strategy 2: Pre-defined REQUIRED_ANCHORS (base product type)
    if super_class in REQUIRED_ANCHORS:
        anchors = REQUIRED_ANCHORS[super_class]
        
        # If no anchors defined, pass
        if not anchors:
            return True, ""
        
        # At least ONE anchor must be present
        for anchor in anchors:
            if anchor in candidate_lower:
                return True, anchor
        return False, ""
    
    # No anchors required = pass
    return True, ""


# ==================== 3) IMPROVED PACK PARSING ====================

def parse_pack_value(product_name: str) -> Optional[float]:
    """Enhanced pack parsing with support for ranges and approximations
    
    Supports:
    - ~5ÐºÐ³, â‰ˆ5ÐºÐ³
    - 4-5 ÐºÐ³, 300-400Ð³
    - 4/5 (weight range)
    - 10Ñ…200, 6x1.5 (multipack)
    - Standard: 1ÐºÐ³, 500Ð³, 2Ð», 250Ð¼Ð»
    
    Returns:
        Pack value in base units (kg/l), or None if cannot parse
    """
    if not product_name:
        return None
    
    name = product_name.lower()
    
    # Pattern 1: Approximate (~, â‰ˆ)
    approx_patterns = [
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*ÐºÐ³', 1.0),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð³', 0.001),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð»', 1.0),
        (r'[~â‰ˆ]\s*(\d+[\.,]?\d*)\s*Ð¼Ð»', 0.001),
    ]
    
    for pattern, multiplier in approx_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                value = float(match.group(1).replace(',', '.'))
                return value * multiplier
            except:
                continue
    
    # Pattern 2: Range (300-400, 4-5)
    range_patterns = [
        (r'(\d+)[-â€“](\d+)\s*ÐºÐ³', 1.0),
        (r'(\d+)[-â€“](\d+)\s*Ð³', 0.001),
        (r'(\d+)[-â€“](\d+)\s*Ð»', 1.0),
        (r'(\d+)[-â€“](\d+)\s*Ð¼Ð»', 0.001),
        (r'(\d+)/(\d+)', 1.0),  # 4/5 (weight category)
    ]
    
    for pattern, multiplier in range_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                val1 = float(match.group(1))
                val2 = float(match.group(2))
                # Use middle of range
                value = (val1 + val2) / 2
                return value * multiplier
            except:
                continue
    
    # Pattern 3: Standard (1ÐºÐ³, 500Ð³, etc.)
    standard_patterns = [
        (r'(\d+[\.,]?\d*)\s*ÐºÐ³', 1.0),
        (r'(\d+[\.,]?\d*)\s*Ð³', 0.001),
        (r'(\d+[\.,]?\d*)\s*Ð»', 1.0),
        (r'(\d+[\.,]?\d*)\s*Ð¼Ð»', 0.001),
        (r'(\d+[\.,]?\d*)\s*ÑˆÑ‚', 1.0),
    ]
    
    for pattern, multiplier in standard_patterns:
        match = re.search(pattern, name)
        if match:
            try:
                value = float(match.group(1).replace(',', '.'))
                return value * multiplier
            except:
                continue
    
    return None


# ==================== 4) BRAND TEXT EXTRACTION ====================

def normalize_brand_text(text: str) -> str:
    """Normalize brand text for matching
    
    - Lowercase
    - Ñ‘â†’Ðµ
    - Remove punctuation, quotes, â„¢, Â®
    - Collapse spaces
    """
    if not text:
        return ""
    
    text = str(text).upper()
    text = text.replace('Ð', 'Ð•').replace('Ñ‘', 'Ðµ')
    
    # Remove trademark symbols
    text = text.replace('â„¢', '').replace('Â®', '').replace('Â©', '')
    
    # Remove punctuation and quotes
    text = re.sub(r'["\'\Â«\Â»\.\,\;\:\!\?]', ' ', text)
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    
    # Collapse spaces
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text.lower()


def extract_brand_from_text(product_name: str, brand_aliases: dict) -> Optional[str]:
    """Extract brand_id from product name using brand_aliases
    
    Args:
        product_name: Product name
        brand_aliases: dict {alias_norm: brand_id}
    
    Returns:
        brand_id or None
    """
    if not product_name or not brand_aliases:
        return None
    
    name_norm = normalize_brand_text(product_name)
    name_words = set(name_norm.split())
    
    # Sort by length (longest first) for better matching
    sorted_aliases = sorted(brand_aliases.items(), key=lambda x: len(x[0]), reverse=True)
    
    for alias_norm, brand_id in sorted_aliases:
        # Short aliases require exact word match
        if len(alias_norm) < 4:
            if alias_norm in name_words:
                return brand_id
        else:
            # Longer aliases - substring at word boundary
            if alias_norm in name_norm:
                # Check word boundary
                pattern = r'(^|\s)' + re.escape(alias_norm) + r'($|\s)'
                if re.search(pattern, name_norm):
                    return brand_id
    
    return None


# Global brand aliases cache
_brand_aliases_cache = None

def load_brand_aliases() -> dict:
    """Load brand aliases from MongoDB
    
    Returns:
        dict {alias_norm: brand_id}
    """
    global _brand_aliases_cache
    
    if _brand_aliases_cache is not None:
        return _brand_aliases_cache
    
    try:
        from pymongo import MongoClient
        import os
        
        DB_NAME = os.environ.get('DB_NAME', 'test_database')
        db = MongoClient(os.environ.get('MONGO_URL'))[DB_NAME]
        
        # Load from brand_aliases collection
        aliases_cursor = db.brand_aliases.find({}, {'_id': 0, 'alias_norm': 1, 'brand_id': 1})
        _brand_aliases_cache = {doc['alias_norm']: doc['brand_id'] 
                                for doc in aliases_cursor if doc.get('alias_norm')}
        
        logger.info(f"ðŸ“š Loaded {len(_brand_aliases_cache)} brand aliases for text extraction")
        
    except Exception as e:
        logger.warning(f"âš ï¸ Could not load brand aliases: {e}")
        _brand_aliases_cache = {}
    
    return _brand_aliases_cache


# ==================== 4) STRUCTURED LOGGING ====================

class SearchLogger:
    """Structured logger for search operations - SAFE (never breaks search)"""
    
    def __init__(self, reference_id: str):
        self.reference_id = reference_id
        self.log_data = {
            'reference_id': reference_id,
            'timestamp': datetime.utcnow().isoformat(),
            'request_context': {},
            'pipeline_counts': {},
            'selection': {},
            'brand_diagnostics': {},
            'outcome': 'unknown'
        }
    
    def set_context(self, **kwargs):
        """SAFE: Set request context"""
        try:
            self.log_data['request_context'].update(kwargs)
        except Exception:
            pass
    
    def set_count(self, stage: str, count: int):
        """SAFE: Set pipeline count"""
        try:
            self.log_data['pipeline_counts'][stage] = count
        except Exception:
            pass
    
    def set_selection(self, **kwargs):
        """SAFE: Set selection data"""
        try:
            self.log_data['selection'].update(kwargs)
        except Exception:
            pass
    
    def set_brand_diagnostics(self, **kwargs):
        """SAFE: Set brand diagnostics"""
        try:
            self.log_data['brand_diagnostics'].update(kwargs)
        except Exception:
            pass
    
    def set_outcome(self, outcome: str, reason_code: str = None):
        """SAFE: Set outcome"""
        try:
            self.log_data['outcome'] = outcome
            if reason_code:
                self.log_data['reason_code'] = reason_code
        except Exception:
            pass
    
    def get_log(self) -> Dict:
        """Get log data"""
        return self.log_data
    
    def log(self):
        """SAFE: Write structured log (never raises)"""
        try:
            logger.info(f"SEARCH_LOG: {json.dumps(self.log_data, ensure_ascii=False)}")
        except Exception as e:
            # Fallback: minimal log
            try:
                logger.warning(f"SearchLogger error: {str(e)}")
            except:
                pass  # Silent fail - logging cannot break search
    
    def set_brand_diagnostics(self, **kwargs):
        """Set brand diagnostics for debugging brand matching"""
        if 'brand_diagnostics' not in self.log_data:
            self.log_data['brand_diagnostics'] = {}
        self.log_data['brand_diagnostics'].update(kwargs)
    
    def set_outcome(self, outcome: str, reason_code: str = None):
        self.log_data['outcome'] = outcome
        if reason_code:
            self.log_data['reason_code'] = reason_code
    
    def get_log(self) -> Dict:
        return self.log_data
    
    def log(self):
        """Write structured log"""
        logger.info(f"SEARCH_LOG: {json.dumps(self.log_data, ensure_ascii=False)}")


# ==================== TESTING ====================

if __name__ == '__main__':
    print("ðŸ§ª P0 Hotfix Components Test\n")
    
    # Test match_percent
    print("1. match_percent clamp:")
    test_values = [0.5, 1.0, 95.0, 150.0, -10.0]
    for val in test_values:
        result = calculate_match_percent(val)
        print(f"   {val:6.1f} â†’ {result} {'âœ…' if 0 <= result <= 100 else 'âŒ'}")
    
    # Test negative keywords
    print("\n2. Negative keywords:")
    test_products = [
        ("Ð“ÐžÐ’Ð¯Ð”Ð˜ÐÐ PRIME 5ÐºÐ³", "meat.beef", False),
        ("Ð ÐÐ¡Ð¢Ð˜Ð¢Ð•Ð›Ð¬ÐÐ«Ð• Ð¡Ð¢Ð Ð˜ÐŸÐ¡Ð« Ð²Ð¼ÐµÑÑ‚Ð¾ Ð³Ð¾Ð²ÑÐ´Ð¸Ð½Ñ‹", "meat.beef", True),
        ("Ð¡Ñ‹Ñ€ Ð¼Ð¾Ñ†Ð°Ñ€ÐµÐ»Ð»Ð° 125Ð³", "dairy.ÑÑ‹Ñ€", False),
        ("Ð¡Ð«Ð ÐÐ˜ÐšÐ˜ 50Ð³", "dairy.ÑÑ‹Ñ€", True)
    ]
    
    for name, sc, expected_negative in test_products:
        has_neg, keyword = has_negative_keywords(name, sc)
        status = "âœ…" if has_neg == expected_negative else "âŒ"
        print(f"   {status} {name[:40]:40} â†’ {has_neg} ('{keyword}')")
    
    # Test pack parsing
    print("\n3. Pack parsing:")
    test_packs = [
        "Ð“Ð¾Ð²ÑÐ´Ð¸Ð½Ð° Ð Ð˜Ð‘ÐÐ™ ~5ÐºÐ³",
        "Ð¡Ð˜Ð‘ÐÐ¡ 300-400Ð³",
        "Ð Ð¸Ñ 4/5 ÐºÐ³",
        "ÐšÐµÑ‚Ñ‡ÑƒÐ¿ 800Ð³",
        "ÐœÐ°ÑÐ»Ð¾ 1,5Ð»"
    ]
    
    for product in test_packs:
        pack = parse_pack_value(product)
        print(f"   {product[:40]:40} â†’ {pack}")
    
    print("\nâœ… All components tested")
