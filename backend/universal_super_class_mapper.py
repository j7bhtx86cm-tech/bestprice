"""
UNIVERSAL Product Name ‚Üí super_class Mapper

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö supplier_items –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è super_class
–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å name_norm.

–õ–æ–≥–∏–∫–∞:
1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ –ø—Ä–æ–¥—É–∫—Ç–∞
2. –ü–æ–∏—Å–∫ –≤ supplier_items —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ–≥–æ super_class —Å—Ä–µ–¥–∏ matches
4. Fallback –Ω–∞ 'other' –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
"""
import os
import re
from pymongo import MongoClient
from collections import Counter

# Global cache
_super_class_cache = None
_db_connection = None

def get_db():
    """Get MongoDB connection"""
    global _db_connection
    if _db_connection is None:
        mongo_url = os.environ.get('MONGO_URL', 'mongodb://localhost:27017')
        db_name = os.environ.get('DB_NAME', 'test_database')
        _db_connection = MongoClient(mongo_url)[db_name]
    return _db_connection

def normalize_text(text):
    """Normalize text for matching"""
    if not text:
        return ""
    text = str(text).lower().strip().replace('—ë', '–µ')
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    return re.sub(r'\s+', ' ', text).strip()

def extract_key_terms(text):
    """Extract key terms from product name"""
    if not text:
        return set()
    
    norm = normalize_text(text)
    words = norm.split()
    
    # Remove stop words and very short words
    stop_words = {'–∏', '–≤', '–Ω–∞', '—Å', '–∏–∑', '–¥–ª—è', '–ø–æ', '–¥–æ', '–æ—Ç', '–∑–∞', '—Å–æ', '–ø–æ–¥'}
    key_terms = {w for w in words if len(w) >= 3 and w not in stop_words}
    
    return key_terms

def build_super_class_index():
    """Build index of keywords ‚Üí super_class from supplier_items
    
    Returns dict: {keyword: {super_class: count}}
    """
    db = get_db()
    
    print("üìö Building super_class index from supplier_items...")
    
    # Get all active supplier_items
    items = list(db.supplier_items.find(
        {'active': True, 'super_class': {'$ne': None, '$ne': 'other'}},
        {'_id': 0, 'name_norm': 1, 'super_class': 1}
    ))
    
    print(f"   Loaded {len(items)} items")
    
    # Build keyword ‚Üí super_class mapping
    keyword_to_classes = {}
    
    for item in items:
        name_norm = item.get('name_norm', '')
        super_class = item.get('super_class')
        
        if not super_class or super_class == 'other':
            continue
        
        # Extract keywords
        keywords = extract_key_terms(name_norm)
        
        for keyword in keywords:
            if keyword not in keyword_to_classes:
                keyword_to_classes[keyword] = Counter()
            keyword_to_classes[keyword][super_class] += 1
    
    print(f"   ‚úÖ Built index: {len(keyword_to_classes)} keywords")
    
    return keyword_to_classes

def get_super_class_index():
    """Get or build super_class index"""
    global _super_class_cache
    if _super_class_cache is None:
        _super_class_cache = build_super_class_index()
    return _super_class_cache

def detect_super_class(product_name, min_confidence=0.3):
    """Detect super_class from product name
    
    Args:
        product_name: Product name (Russian)
        min_confidence: Minimum confidence threshold (0..1), default 0.3
    
    Returns:
        (super_class, confidence) or (None, 0.0)
    """
    if not product_name:
        return None, 0.0
    
    name_norm = normalize_text(product_name)
    
    # DIRECT MAPPINGS (high priority, confidence=1.0)
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è 'other' —Å 29% –¥–æ <10%
    direct_map = {
        # Condiments & Sauces
        '–∫–µ—Ç—á—É–ø': 'condiments.ketchup',
        '–º–∞–π–æ–Ω–µ–∑': 'condiments.mayo',
        '—Å–æ—É—Å': 'condiments.sauce',
        '–≥–æ—Ä—á–∏—Ü': 'condiments.mustard',
        '—Ö—Ä–µ–Ω': 'condiments.horseradish',
        '–∞–¥–∂–∏–∫': 'condiments.adjika',
        
        # Spices & Seasonings
        '–≤–∞—Å–∞–±–∏': 'condiments.spice',
        '–±–∞–¥—å—è–Ω': 'condiments.spice',
        '–∫–∞—Ä–¥–∞–º–æ–Ω': 'condiments.spice',
        '–∫–æ—Ä–∏—Ü–∞': 'condiments.spice',
        '–∞–Ω–∏—Å': 'condiments.spice',
        '–≥–≤–æ–∑–¥–∏–∫': 'condiments.spice',
        '–∫–æ—Ä–∏–∞–Ω–¥—Ä': 'condiments.spice',
        '–∫—É—Ä–∫—É–º': 'condiments.spice',
        '–ø–∞–ø—Ä–∏–∫': 'condiments.spice',
        '–ø–µ—Ä–µ—Ü': 'condiments.spice',
        '–ø—Ä—è–Ω–æ—Å—Ç': 'condiments.spice',
        '—Å–ø–µ—Ü–∏': 'condiments.spice',
        '–ø—Ä–∏–ø—Ä–∞–≤': 'condiments.seasoning',
        '–∑–∞–ø—Ä–∞–≤–∫': 'condiments.seasoning',
        
        # Oils
        '–∫—É–Ω–∂—É—Ç': 'oils.sesame',
        '—Ç—ã–∫–≤–µ–Ω': 'oils.pumpkin',
        '—Ñ—Ä–∏—Ç—é—Ä': 'oils.frying',
        '–æ–ª–∏–≤–∫–æ–≤': 'staples.–º–∞—Å–ª–æ.–æ–ª–∏–≤–∫–æ–≤–æ–µ',
        '–ø–æ–¥—Å–æ–ª–Ω–µ—á': 'oils.sunflower',
        '—Ä–∞–ø—Å–æ–≤': 'oils.rapeseed',
        
        # Seafood
        '—Å–∏–±–∞—Å': 'seafood.seabass',
        '—Å–∏–±–∞—Å—Å': 'seafood.seabass',
        '–ª–æ—Å–æ—Å—å': 'seafood.salmon',
        '—Å—ë–º–≥–∞': 'seafood.salmon',
        '—Ñ–æ—Ä–µ–ª—å': 'seafood.trout',
        '–∫—Ä–µ–≤–µ—Ç–∫': 'seafood.shrimp',
        '–¥–æ—Ä–∞–¥–æ': 'seafood.seabream',
        '–¥–æ—Ä–∞–¥–∞': 'seafood.seabream',
        '—Ç—É–Ω–µ—Ü': 'canned.—Ç—É–Ω–µ—Ü.–∫–æ–Ω—Å–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–π',
        '–º–∏–Ω—Ç–∞–π': 'seafood.pollock',
        '—Ç—Ä–µ—Å–∫–∞': 'seafood.cod',
        '–∫–∞–º–±–∞–ª': 'seafood.flounder',
        '–ø–∞–ª—Ç—É—Å': 'seafood.halibut',
        '—Å–∫—É–º–±—Ä': 'seafood.mackerel',
        '—Å–µ–ª—å–¥': 'seafood.herring',
        '–∞–Ω—á–æ—É—Å': 'seafood.anchovy',
        '–∫–∞–ª—å–º–∞—Ä': 'seafood.squid',
        '–æ—Å—å–º–∏–Ω–æ–≥': 'seafood.octopus',
        '–º–∏–¥–∏–∏': 'seafood.mussels',
        '–≥—Ä–µ–±–µ—à–æ–∫': 'seafood.scallop',
        '–∏–∫—Ä–∞': 'seafood.caviar',
        
        # Meat
        '–≥–æ–≤—è–¥–∏–Ω–∞': 'meat.beef',
        '—Å–≤–∏–Ω–∏–Ω–∞': 'meat.pork',
        '–∫—É—Ä–∏—Ü–∞': 'meat.chicken',
        '–∏–Ω–¥–µ–π–∫–∞': 'meat.turkey',
        '—è–≥–Ω—è—Ç–∏–Ω–∞': 'meat.lamb',
        '—É—Ç–∫–∞': 'meat.duck',
        '—Ñ–∞—Ä—à': 'meat.ground',
        '–∫–æ–ª–±–∞—Å': 'meat.kolbasa',
        '—Å–æ—Å–∏—Å–∫': 'meat.sausage',
        '–≤–µ—Ç—á–∏–Ω': 'meat.ham',
        
        # Additives
        '–∂–µ–ª–∞—Ç–∏–Ω': 'additives.gelatin',
        '–≥–ª—É—Ç–∞–º–∞—Ç': 'additives.msg',
        '–∫–æ–∫–æ—Å–æ–≤': 'additives.coconut',
        '–∫—Ä–∞—Ö–º–∞–ª': 'additives.starch',
        '—Ä–∞–∑—Ä—ã—Ö–ª–∏—Ç–µ–ª': 'additives.baking_powder',
        '—Å–æ–¥–∞': 'additives.baking_soda',
        '—É–∫—Å—É—Å': 'condiments.vinegar',
        '–ª–∏–º–æ–Ω–Ω': 'additives.citric_acid',
        
        # Pickles & Preserves
        '—Ä–µ–ª–∏—à': 'condiments.relish',
        '–æ–≥—É—Ä—Ü': 'canned.–æ–≥—É—Ä—Ü—ã',
        '–ø–æ–º–∏–¥–æ—Ä': 'canned.—Ç–æ–º–∞—Ç—ã.–∫–æ–Ω—Å–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ',
        '—Ç–æ–º–∞—Ç': 'canned.—Ç–æ–º–∞—Ç—ã.–∫–æ–Ω—Å–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ',
        '–æ–ª–∏–≤–∫': 'canned.–æ–ª–∏–≤–∫–∏',
        '–∫–∞–ø–µ—Ä—Å': 'canned.–∫–∞–ø–µ—Ä—Å—ã',
        '–∫–æ—Ä–Ω–∏—à–æ–Ω': 'canned.–æ–≥—É—Ä—Ü—ã'
    }
    
    # Check direct mappings first
    for key, super_class in direct_map.items():
        if key in name_norm:
            return super_class, 1.0
    
    # Fallback to keyword-based detection
    index = get_super_class_index()
    
    # Extract keywords from product name
    keywords = extract_key_terms(product_name)
    
    if not keywords:
        return None, 0.0
    
    # Collect all super_class candidates from keywords
    class_votes = Counter()
    
    for keyword in keywords:
        if keyword in index:
            # Add votes from this keyword
            for super_class, count in index[keyword].items():
                class_votes[super_class] += count
    
    if not class_votes:
        return None, 0.0
    
    # Get top candidate
    top_class, top_votes = class_votes.most_common(1)[0]
    
    # Calculate confidence
    total_votes = sum(class_votes.values())
    confidence = top_votes / total_votes if total_votes > 0 else 0.0
    
    if confidence < min_confidence:
        return None, confidence
    
    return top_class, confidence

# For backward compatibility
def detect_product_core(product_name):
    """Legacy interface - returns super_class for compatibility"""
    super_class, confidence = detect_super_class(product_name)
    return super_class

# Test if run directly
if __name__ == '__main__':
    test_products = [
        "–ö–µ—Ç—á—É–ø —Ç–æ–º–∞—Ç–Ω—ã–π 800 –≥—Ä. Heinz",
        "–ì–æ–≤—è–¥–∏–Ω–∞ —Ñ–∞—Ä—à 80/20 5 –∫–≥",
        "–õ–û–°–û–°–¨ —Ñ–∏–ª–µ —Ç—Ä–∏–º D –ß–∏–ª–∏ —Å/–º –≤–µ—Å 1.5 –∫–≥",
        "–ö—Ä–µ–≤–µ—Ç–∫–∏ 16/20 –≤–∞—Ä–µ–Ω–æ-–º–æ—Ä–æ–∂–µ–Ω—ã–µ 1 –∫–≥",
        "–°–ò–ë–ê–° —Ü–µ–ª—ã–π 300-400 –≥—Ä",
        "–ú–∞—Å–ª–æ –æ–ª–∏–≤–∫–æ–≤–æ–µ Extra Virgin 1 –ª",
        "–ú—É–∫–∞ –ø—à–µ–Ω–∏—á–Ω–∞—è –≤—ã—Å—à–∏–π —Å–æ—Ä—Ç 2 –∫–≥"
    ]
    
    print("\nüß™ Testing super_class detection:\n")
    for product in test_products:
        super_class, confidence = detect_super_class(product)
        status = "‚úÖ" if super_class else "‚ùå"
        print(f"{status} {product[:50]:50} ‚Üí {super_class or 'NONE':30} (conf: {confidence:.2f})")
